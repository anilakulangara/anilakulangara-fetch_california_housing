{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63414f20-7082-4e93-ad24-9c911f5bfc41",
   "metadata": {},
   "source": [
    "## Load and Convert to DataFrame\n",
    "The fetch_california_housing dataset contains information about housing in California, including features like population, median income, and house age. It comes in dictionary format, so we will convert it into a pandas DataFrame.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa058d-767a-4e3d-9cec-d5aa09d904ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the California Housing dataset\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "dataset = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bbc457-addf-45f7-b0da-75b3d8b3f508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a DataFrame\n",
    "\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['Target'] = dataset.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b8bf5e-8ef9-4636-9892-cfe649f9b4ea",
   "metadata": {},
   "source": [
    "## Handle Missing Values\n",
    "The dataset typically does not contain missing values, but we will verify and handle them if necessary. If missing values exist, we can:\n",
    "\n",
    "Use mean/median imputation for numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44ffe41-62de-4395-842c-b2928f780b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardisation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "object= StandardScaler()\n",
    "X_scale = object.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0a41c-5d3b-43b0-a52a-ebf42f8502a3",
   "metadata": {},
   "source": [
    "As there are no missing values we can proceed with this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e4c71-459a-47a0-97a0-45dfb2beca30",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Feature scaling is crucial because:\n",
    "\n",
    "The dataset contains features like house age (small range) and median income (larger range).\n",
    "Algorithms like gradient descent-based models (e.g., Linear Regression, Neural Networks) and distance-based models (e.g., k-NN, SVMs) perform better when features are standardized.\n",
    "We will apply Standardization (Z-score normalization).\n",
    "\n",
    "\n",
    "Standardization formula: $X' = \\frac{X - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced46a9e-2740-42f3-8958-9b939769b165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.34476576,  0.98214266,  0.62855945, ...,  1.05254828,\n",
       "        -1.32783522,  2.12963148],\n",
       "       [ 2.33223796, -0.60701891,  0.32704136, ...,  1.04318455,\n",
       "        -1.32284391,  1.31415614],\n",
       "       [ 1.7826994 ,  1.85618152,  1.15562047, ...,  1.03850269,\n",
       "        -1.33282653,  1.25869341],\n",
       "       ...,\n",
       "       [-1.14259331, -0.92485123, -0.09031802, ...,  1.77823747,\n",
       "        -0.8237132 , -0.99274649],\n",
       "       [-1.05458292, -0.84539315, -0.04021111, ...,  1.77823747,\n",
       "        -0.87362627, -1.05860847],\n",
       "       [-0.78012947, -1.00430931, -0.07044252, ...,  1.75014627,\n",
       "        -0.83369581, -1.01787803]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2eb436b-1667-4484-a114-e856a613afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear Regression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scale, dataset.target, test_size=0.33, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cac8d8-9663-46f5-9f79-d81812c7c532",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "### How It Works:\n",
    "Linear Regression finds the best-fitting line to predict the target variable \n",
    "ùëå based on features ùëã\n",
    "\n",
    "The equation for Linear Regression is $Y = w_1X_1 + w_2X_2 + ... + w_nX_n + b$.\n",
    "where \n",
    "ùë§\n",
    "ùëñ\n",
    "w \n",
    "i\n",
    "‚Äã\n",
    "  are weights (coefficients) and \n",
    "ùëè\n",
    "b is the intercept.\n",
    "\n",
    "It minimizes the Mean Squared Error (MSE) to find the best line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de871508-173b-49b7-9fe9-1d6c1db7a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf820b6b-f401-4a5b-bcd1-963e0c2c1750",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "\n",
    "The Mean Squared Error (MSE) is given by the formula:\n",
    "\n",
    "$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$\n",
    "\n",
    " \n",
    "Measures the average squared difference between actual and predicted values.\n",
    "\n",
    "Penalizes large errors more than small ones because of squaring.\n",
    "\n",
    "Lower MSE means better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea1e21-57ff-428c-a296-76dec7f100af",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "    \n",
    "Measures the absolute difference between actual and predicted values.\n",
    "    \n",
    "Unlike MSE, it doesn‚Äôt penalize large errors more than small errors.\n",
    "    \n",
    "Lower MAE means better model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36401b0-37a3-45c9-803d-1b7d8172e3bf",
   "metadata": {},
   "source": [
    "## R-squared Score (ùëÖ^2)\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "The **R-squared (R¬≤)** score represents how well the model explains the variance in the data.\n",
    "\n",
    "- $R^2 = 1$: The model perfectly explains the data.\n",
    "- $R^2 = 0$: The model explains none of the variance (equivalent to predicting the mean).\n",
    "- $R^2 < 0$: The model is worse than simply predicting the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7795be5b-030b-4781-ae7e-f551b6900b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2446582939033036e-30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c57c2a-6538-4f63-a165-384b72be0289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.059825419507913e-16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b640cc-cc9c-4aff-8b17-9070c7c5fe84",
   "metadata": {},
   "source": [
    " This is an extremely small value, essentially close to zero. A very low MSE indicates that the model's predictions are extremely close to the actual values, and the model has very little error.\n",
    "This indicates excellent performance, with almost no discrepancy between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e9fee35-8917-4fc3-8237-6c7d48ce9938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3afb0a-cd6e-4dc3-8595-65c0bb86d0ef",
   "metadata": {},
   "source": [
    "This is also an extremely small value, indicating that the average absolute difference between the predicted and actual values is almost negligible.\n",
    " Like the MSE, this suggests minimal error and indicates that the model has performed very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42c6acd-5947-473e-91fe-ea271fc01073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)  \n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071faa9b-3039-47bf-9f2e-ce341d5d575b",
   "metadata": {},
   "source": [
    "An R^2 score of 1.0 means that the model explains 100% of the variance in the target variable. The model has perfectly fitted the data and explains the relationship between the features and the target perfectly.\n",
    "This indicates that the model has perfectly captured the data's underlying pattern and provides the best possible fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2b2fb-40f5-4757-8efa-fb7c804b7f25",
   "metadata": {},
   "source": [
    "The results suggest that the model has excellent performance:\n",
    "\n",
    "It makes very accurate predictions, with negligible error (both MSE and MAE are extremely small).\n",
    "The model explains the target variable perfectly, as evidenced by the \n",
    "ùëÖ^2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0db14db-0a08-4a05-b590-7d78194f3876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8403552701115834e-06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred_dt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc9988-1019-4713-8d1f-83a3405245a4",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "### How It Works:\n",
    "A Decision Tree splits data based on feature values, creating a tree-like structure.\n",
    "\n",
    "It chooses splits that minimize variance in each subset.\n",
    "\n",
    "The final predictions are made by taking the average of values in each leaf node.\n",
    "\n",
    "Decision Trees capture non-linear relationships in data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb527794-0349-43b5-b42b-0abeacaaaa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003097489724045361"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred_dt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908cf55-1071-4da1-8837-c31d099747da",
   "metadata": {},
   "source": [
    "This is a very small value, indicating that the model's predictions are extremely close to the actual values. However, it's still greater than zero, so there is some small error, but it's negligible in practical terms.\n",
    "The model has very low error, but there may still be slight discrepancies between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe298fd-79bf-40d0-b798-16b8fe774dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999986189132986"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred_dt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ccd3e-8077-41e4-abb6-5b69f4ec2faa",
   "metadata": {},
   "source": [
    " This value is very small, indicating that on average, the model's predictions deviate from the actual values by just a tiny amount.\n",
    "This is a sign of excellent predictive accuracy. The model is very close to the actual values on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24018e68-f279-4c3e-9c88-78056e24e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)  \n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82afaac-5dac-40f4-8238-6bbba244db76",
   "metadata": {},
   "source": [
    "An R^2 score of 0.9999986 means the model explains almost 100% of the variance in the data. This is a very high score, suggesting that the model has captured the underlying patterns in the data with remarkable precision.This indicates an excellent fit of the model to the data, meaning the Decision Tree Regressor has learned the relationships between the features and target variable very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627456ea-4aec-49b2-bef9-1f7d81a7c10c",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "### How It Works:\n",
    "It is an ensemble of Decision Trees, where multiple trees are trained on different data samples (bagging).\n",
    "\n",
    "Predictions are made by averaging outputs from all trees.\n",
    "\n",
    "Reduces overfitting and improves accuracy compared to a single Decision Tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb2cb0b4-9f7a-4010-9391-6fc4ad50426d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1978431515986009e-06"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3e5916-fb19-4ad9-90a2-f654a896f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002538481062841674"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13e9d9-b136-4f91-aeb0-2fb03b1532b9",
   "metadata": {},
   "source": [
    "The Random Forest model has made predictions with very low error, which suggests good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6140cd-292f-481a-9db7-227d38ca3fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999991010612432"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a41df-1d40-4e13-a2d7-6280a416dc99",
   "metadata": {},
   "source": [
    "The MAE is also very small, showing that the average difference between the predicted and actual values is minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4c901-f6ec-4c15-9b1a-acc9cd0d4cf0",
   "metadata": {},
   "source": [
    "r2_score(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef4660-0501-4fae-96a7-0f4486dca5db",
   "metadata": {},
   "source": [
    "An \n",
    "ùëÖ^\n",
    "2\n",
    "score of 0.9999991 indicates that the model explains almost 100% of the variance in the data, suggesting that the Random Forest Regressor has fitted the data very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d141cab-81c2-4e80-8a09-eddac57b4762",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor\n",
    "### How It Works:\n",
    "\n",
    "Uses Boosting, meaning it builds trees sequentially, with each new tree correcting errors from the previous ones.\n",
    "    \n",
    "It minimizes residual errors using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf04243-82b0-4e4d-b53f-3dfc390275eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.276096209518953e-05"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred_gb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25412bcd-1998-47a4-a208-7a6fbfed6848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0061615204489604"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred_gb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfda8de-8c61-4f45-af04-fdad1f55f093",
   "metadata": {},
   "source": [
    "The MSE is small but larger than the values seen in other models, indicating that the Gradient Boosting model has some residual error in its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "702de301-6cbe-46a3-8ba2-eafa64db8771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999453992473412"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred_gb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b73c1-8477-4281-9be8-f723bab2dbb2",
   "metadata": {},
   "source": [
    "This value shows that on average, the predictions deviate from the actual values by around 0.006. While still small, this suggests that the model's predictions are less accurate compared to the extremely low MAE seen in other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f2e0464-316f-4bc9-ac78-7d0d9158fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)  # Needs scaling\n",
    "y_pred_svr = svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38642042-3796-4dbf-8bea-6f38314f1227",
   "metadata": {},
   "source": [
    "The value is very close to 1, meaning the model explains nearly 100% of the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5b876-55d9-4ae1-b2c1-ae3407530f3e",
   "metadata": {},
   "source": [
    "## Support Vector Regressor (SVR)\n",
    "### How It Works:\n",
    "\n",
    "SVR finds a hyperplane that best fits the data, with a margin of tolerance (ùúñ).\n",
    "\n",
    "Uses kernel trick (e.g., RBF kernel) to model non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e425ee05-a42b-4e18-b0bf-4221406c0386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00564516069778184"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred_svr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dea03d14-9274-40c4-ae66-1b1ce70c227f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05361453748098604"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred_svr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73b7407f-b5a0-4d6e-8b17-ac9e5c89da9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9958713606071191"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred_svr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a6fb0-4244-42ea-a957-2f24c0f4af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Low error values in both MSE and MAE \n",
    "Very high R¬≤ score, showing that the model captures the majority of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e5798-bc4c-40a6-bcdb-69d979158bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591caff5-b0dc-44d1-b613-9214f3e563b2",
   "metadata": {},
   "source": [
    "# Final conclusion\n",
    "\n",
    "## Based on the metrics, All models works good but Linear Regressor is the best performing model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
